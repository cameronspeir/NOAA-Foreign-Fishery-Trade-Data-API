---
title: 'Using Stata to Access the Fishery Foreign Trade API: Part 2, Filtering'
author: "Cameron Speir"
date: "8/25/2020"
output:
  pdf_document: default
  html_document: default
---

## Do Part 1 First
The first vignette on using Stata to access the Fishery Foreign Trade API covered the basics, including a refresher on macros, simple data retrieval, and specifying the limit parameter.  In this vignette, we will look at constructing a url to filter the data.  This is much more difficult because Stata can sometimes misinterpret special characters that we need to include in the url.  We will take a look at how the filtering syntax works and introduce Unicode text characters a way to make sure we are builing the right urls.


## Filtering the data
The real usefulness of the API with these data is filtering to get a very specific subset.  Here is an example of the URL you would use to filter on year, e.g., to get all data from 2011 onwards:

```
https://apps-st.fisheries.noaa.gov/ods/foss/trade_data/?q={"year":{"\$gt": 2010}}
```

If you copy and paste that link into a brower, it will return those specific data. 

The grammar for this type of filter is pretty specific and wasn't familar to me.  For example, "\$gt" means "greater than".  For a list of filter operators you can use, check out "3.2.5.2.1 FilterObject Grammar" at this link: <https://docs.oracle.com/cd/E56351_01/doc.30/e87809/developing-REST-applications.htm#AELIG90103>


## Problem: Getting Stata to pass url's containing special characters
Certain text characters have very specific meanings in the Stata programming language.  Dollar signs have something to do with macros, for example, which is a problem because the filtering grammer used by the API contains a lot of dollar signs.  Also, Stata is very particular about quotation marks are used.  This is also a problem for us becuase query parameters that filter on variables are replete with quotation marks.  All kinds of thing can go wrong when trying to pass url's like this using Stata.
<br>

## Solution: Unicode text
Unicode is a standard for encoding characters.  An encoding system is a way of representing a character as a byte or series of bytes.  Examples of encoding systems are ASCII and UTF-8.  UTF-8 is a particular flavor of unicode (ASCII is not a Unicode system).  Unicode is great because it has ways of representing an enormous number of characters in just about any language.  Think of all those French accents.  There is a specific unicode character for each letter-accent combination.
<br>

In our context, Unicode representations of specific characters are useful because some special characters in Stata (notably, quotation marks and dollar signs) can be misinterpreted by Stata when we use them in a url we want to send to the server as an API request.  
<br>

Substituting unicode characters into the url we send can solve these problems.  The server reads the the unicode characters that are stuck into the url and is perfectly OK with that.  And we we never have to show Stata any potentially confusing things like dollar signs. For each text character you want to replace with Unicode, swap it out with "%XX" where "XX" is the two-character UTF-8 code.

## List of Unicode Characters
Wikipedia has a pretty good list of Unicode characters.
<https://en.wikipedia.org/wiki/List_of_Unicode_characters>
Use the last two characters in the UTF-8 code listed in the tables to replace a text character.  For example, to replace an exclamation point, "!", use "%21" in the url.  Note that the UTF-8 code listed in the tables is "U+0021".
<br>

Some incredibly useful codes for working with Stata special characters include:

* %20   empty space
* %22 " quotation mark
* %24 \$ dollar sign
* %25 % percent sign
* %26 & ampersand

<br>

# Example 1: Simple filter on the "year" variable
Let's build a query to filter on year, returning observations from 2011- to present
```
https://apps-st.fisheries.noaa.gov/ods/foss/trade_data/?q={"year":{"\$gt": 2010}}
```
The quotation marks and the dollar sign are problematic.

**Before you do anything else, remember to create an empty data set and define your invars macro, as we did in the first vignette.**
<br>
We'll define a macro for the root url and the query paramter, then stick them together into the request url.  When we do this, "%22" is the unicode character for double quotation marks and "%24" represents"$".

```
* local url_root https://apps-st.fisheries.noaa.gov/ods/foss/trade_data/ ;
* local query_unicode ?q={%22year%22:{%22%24gt%22:2010}};
* local request_unicode `url_root'`query_param';
```
Send your request to the server and let insheetjson covert from json to a Stata datas set.
```
insheetjson `invars'
	using "`request_unicode'",
	column("year" "month" "hts_number" "name" "cntry_code" "fao" "cntry_name" 
			"district_code" "district_name" "edible_code" "kilos" "val" 
			"source" "association" "rfmo" "nmfs_region_code") tableselector("items");

* take a look at the result;
describe;
```


# Example 2: More complex filters on multiple variables
The grammar used for filtering for this API can get complicated when there are multiple variables and logical operators involved.  Let's try this:

### Salmon exports from Seattle in 2016
We need to filter on four variables:

* "name" contains "SALMON" (case sensitive) 
* "source" is equal to "EXP"
* "district_name" is equal to "SEATTLE, WA"
* "year" is equal to 2016

We need to build this URL:

```
https://apps-st.fisheries.noaa.gov/ods/foss/trade_data/?q={"name":{"\$like":"%25SALMON%25"},
"source":"EXP","district_name":"SEATTLE, WA","year":"2016"}
```

Here's how we will do it:

```
local url_root https://apps-st.fisheries.noaa.gov/ods/foss/trade_data/;
local query_SEA_SAMN ?q={%22year%22:2016,%22name%22:{%22%24like%22:%22%25SALMON%25%22},
%22source%22:%22EXP%22,%22district_name%22:%22SEATTLE,%20WA%22};
local request_SEA_SAMN `url_root'`query_SEA_SAMN';
```

```
insheetjson `invars'
	using "`request_SEA_SAMN'",
	column(`quote_invars') tableselector("items");
```

Take a look ad the api_example_filtering2.do code.